{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063ee124",
   "metadata": {},
   "source": [
    "# Data Preprocessing for VinDr-Mammo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313ed8c",
   "metadata": {},
   "source": [
    "## Step 0: Download the Dataset\n",
    "1. Download the dataset from [VinDr-Mammo on PhysioNet](https://www.physionet.org/content/vindr-mammo/1.0.0/).\n",
    "2. Place the images in the following directory:\n",
    "\n",
    "    ```\n",
    "    /workspace/data/VinDr-Mammo/images\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7be17",
   "metadata": {},
   "source": [
    "## Step 1: Convert DICOM to NIfTI\n",
    "The following step converts the DICOM files located in ``/workspace/data/VinDr-Mammo/images`` to NIfTI format and saves them in ``/workspace/data/VinDr-Mammo/nifti``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2aa1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9547df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/workspace/data/VinDr-Mammo'\n",
    "dcm_root = os.path.join(root, 'images')\n",
    "result_root = os.path.join(root, 'nifti')\n",
    "\n",
    "pats = os.listdir(dcm_root)\n",
    "for pat in tqdm(pats):\n",
    "    imgs = os.listdir(os.path.join(dcm_root, pat))\n",
    "\n",
    "    output_folder = os.path.join(result_root, pat)\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "    for img in imgs:\n",
    "        if \"dicom\" not in img:\n",
    "            continue\n",
    "        img_path = os.path.join(dcm_root, pat, img)\n",
    "        dcm_data = pydicom.read_file(img_path)\n",
    "        view = dcm_data[0x0018, 0x5101].value\n",
    "        laterality = dcm_data[0x0020, 0x0062].value\n",
    "        \n",
    "        output_path = os.path.join(output_folder, laterality+\"_\"+view+\".nii.gz\")\n",
    "        img_sitk = sitk.ReadImage(img_path)\n",
    "        sitk.WriteImage(img_sitk, output_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6757c",
   "metadata": {},
   "source": [
    "## Step 2: Get Bounding Box Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac6a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/workspace/data/VinDr-Mammo'\n",
    "img_root = os.path.join(root, 'nifti')\n",
    "result_root = os.path.join(root, 'bbox_nifti')\n",
    "\n",
    "os.makedirs(result_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_all = pd.read_csv(os.path.join(root, 'finding_annotations.csv'))\n",
    "findings = findings_all[findings_all['finding_categories'] != \"['No Finding']\"]\n",
    "findings['finding_num'] = findings.groupby('image_id').cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a706fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "findings.to_csv(os.path.join(root, 'finding_annotations+finding_num.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871be280",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(findings.iterrows()):\n",
    "    pat_id = row[1]['study_id']\n",
    "    view = row[1]['view_position']\n",
    "    LR = row[1]['laterality']\n",
    "    finding_num = row[1]['finding_num']\n",
    "    ymin = math.floor(row[1]['ymin'])\n",
    "    ymax = math.ceil(row[1]['ymax'])\n",
    "    xmin = math.floor(row[1]['xmin'])\n",
    "    xmax = math.ceil(row[1]['xmax'])\n",
    "    if pd.isna(row[1]['finding_birads']):\n",
    "        # print(row[0], \",,,finding briads is NaN,,,\", row[1]['finding_categories'])\n",
    "        continue\n",
    "    birads = row[1]['finding_birads'].replace(\" \", \"-\")\n",
    "    finding_list = ast.literal_eval(row[1]['finding_categories'])\n",
    "    finding_list = [s.replace(' ', '-') for s in finding_list]\n",
    "    # if \"Mass\" not in finding_list:\n",
    "        # continue\n",
    "    \n",
    "    img_path = os.path.join(img_root, pat_id, LR+\"_\"+view+\".nii.gz\")\n",
    "    if not os.path.isfile(img_path):\n",
    "        # print(row[0], pat_id, \",,,image not found,,,\")\n",
    "        continue\n",
    "    img_arr = sitk.GetArrayFromImage(sitk.ReadImage(img_path))\n",
    "\n",
    "    bbox = np.zeros_like(img_arr)\n",
    "    bbox[:,ymin:ymax+1,xmin:xmax+1] = 1\n",
    "    if not np.any(bbox):\n",
    "        print(row[0], pat_id, \",,,empty bbox,,,\")\n",
    "    \n",
    "    output_folder = os.path.join(result_root, pat_id)\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "    \n",
    "    filename = LR + \"_\" + view + \"_bbox-\" + str(finding_num) + \"_\" + birads + \"_\" + '+'.join(finding_list) + \".nii.gz\"\n",
    "    # filename = LR + \"_\" + view + \"_bbox-\" + str(finding_num) + \"_\" + birads + \"_Mass.nii.gz\"\n",
    "    bbox_sitk = sitk.GetImageFromArray(bbox)\n",
    "    sitk.WriteImage(bbox_sitk, os.path.join(output_folder, filename))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a126de86",
   "metadata": {},
   "source": [
    "## Step 3: Crop Breast Mask\n",
    "Crops the image to retain only the breast area using Otsu's thresholding after Gaussian filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.exposure import equalize_adapthist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(data, mask=None):\n",
    "    # Otsu's thresholding after Gaussian filtering\n",
    "    img_blurred = gaussian(data, sigma=10)\n",
    "    thresh = threshold_otsu(img_blurred)\n",
    "    breast_mask = (img_blurred > thresh).astype(np.uint8)\n",
    "    labeled_img = label(breast_mask)\n",
    "    regions = regionprops(labeled_img)\n",
    "    largest_region = max(regions, key=lambda x: x.area)\n",
    "    minr, minc, maxr, maxc = largest_region.bbox\n",
    "    \n",
    "    if mask is None: \n",
    "        return data[minr:maxr, minc:maxc], breast_mask[minr:maxr, minc:maxc]\n",
    "    else:\n",
    "        return data[minr:maxr, minc:maxc], breast_mask[minr:maxr, minc:maxc], mask[minr:maxr, minc:maxc]\n",
    "\n",
    "def minmax_normalization(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def truncation_normalization(data, mask):\n",
    "    \"\"\"\n",
    "    Pixel clipped and normalized in breast ROI\n",
    "    \"\"\"\n",
    "    Pmin = np.percentile(data[mask!=0], 5)\n",
    "    Pmax = np.percentile(data[mask!=0], 99)\n",
    "    truncated = np.clip(data,Pmin, Pmax)  \n",
    "    normalized = (truncated - Pmin)/(Pmax - Pmin)\n",
    "    normalized[mask==0]=0\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def clahe(data, clip_limit=0.01):\n",
    "    #contrast enhancement\n",
    "    return equalize_adapthist(data, clip_limit=clip_limit)\n",
    "\n",
    "def save_comparison_images(original_arr, mammogram_arr, breast_mask, file_path, mass_mask=None):\n",
    "\n",
    "    if mass_mask is not None:\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 80))\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(20, 60))\n",
    "\n",
    "    axs[0].imshow(original_arr, cmap='gray')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    axs[1].imshow(mammogram_arr, cmap='gray', vmax=1, vmin=0)\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(breast_mask, cmap='gray', vmax=1, vmin=0)\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    if mass_mask is not None:\n",
    "        axs[3].imshow(mass_mask, cmap='gray', vmax=1, vmin=0)\n",
    "        axs[3].axis('off')\n",
    "\n",
    "    plt.savefig(file_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(\"all\")\n",
    "\n",
    "def Read_nifti(img_path):\n",
    "    img_sitk = sitk.ReadImage(img_path)\n",
    "    return sitk.GetArrayFromImage(img_sitk)[0], img_sitk.GetSpacing()\n",
    "\n",
    "def Save_nifti(img_arr, save_path, spacing=None):\n",
    "    img_sitk = sitk.GetImageFromArray(img_arr)\n",
    "    if spacing is not None:\n",
    "        img_sitk.SetSpacing(spacing)\n",
    "    sitk.WriteImage(img_sitk, save_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd63d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/workspace/data/VinDr-Mammo'\n",
    "img_root = os.path.join(root, 'nifti')\n",
    "pats = os.listdir(img_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_error = []\n",
    "\n",
    "for pat in tqdm(pats):\n",
    "    imgs = os.listdir(os.path.join(img_root, pat))\n",
    "    for img in imgs:\n",
    "        img_path = os.path.join(img_root, pat, img)\n",
    "\n",
    "        img_arr, spacing = Read_nifti(img_path)\n",
    "        \n",
    "        mammogram, breast_mask = crop(img_arr)\n",
    "        mammogram = minmax_normalization(mammogram)\n",
    "        \n",
    "        if np.all(breast_mask==1):\n",
    "            print(\"ERROR in cropping,,,\", pat, img)\n",
    "            crop_error.append(pat+\"_\"+img)\n",
    "            continue\n",
    "\n",
    "        pat_folder = os.path.join(root, 'cropped_nifti', pat)\n",
    "        os.makedirs(pat_folder, exist_ok=True)\n",
    "\n",
    "        mammogram_path = os.path.join(pat_folder, img)\n",
    "        breast_mask_path = os.path.join(pat_folder, img.split(\".\")[0]+\"-breask_mask.nii.gz\")\n",
    "        \n",
    "        Save_nifti(mammogram, mammogram_path, spacing=spacing)\n",
    "        Save_nifti(breast_mask, breast_mask_path, spacing=spacing)\n",
    "\n",
    "        plot_path = os.path.join(root, 'cropped_check_all', pat+\"_\"+img.split(\".\")[0]+\".png\")\n",
    "        os.makedirs(os.path.join(root, 'cropped_check_all'), exist_ok=True)\n",
    "        save_comparison_images(img_arr, mammogram, breast_mask, plot_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bbd62e",
   "metadata": {},
   "source": [
    "## Step 3-1: Get Mass Mask using MedSAM\n",
    "As the mass masks used in this paper are not provided, we offer code to extract mass masks using MedSAM based on bounding boxes. This is based on the code from the [MedSAM repository](https://github.com/bowang-lab/MedSAM.git)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% environment and functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from segment_anything import sam_model_registry\n",
    "from skimage import io, transform\n",
    "import torch.nn.functional as F\n",
    "import SimpleITK as sitk\n",
    "\n",
    "@torch.no_grad()\n",
    "def medsam_inference(medsam_model, img_embed, box_1024, H, W):\n",
    "    box_torch = torch.as_tensor(box_1024, dtype=torch.float, device=img_embed.device)\n",
    "    if len(box_torch.shape) == 2:\n",
    "        box_torch = box_torch[:, None, :] # (B, 1, 4)\n",
    "\n",
    "    sparse_embeddings, dense_embeddings = medsam_model.prompt_encoder(\n",
    "        points=None,\n",
    "        boxes=box_torch,\n",
    "        masks=None,\n",
    "    )\n",
    "    low_res_logits, _ = medsam_model.mask_decoder(\n",
    "        image_embeddings=img_embed, # (B, 256, 64, 64)\n",
    "        image_pe=medsam_model.prompt_encoder.get_dense_pe(), # (1, 256, 64, 64)\n",
    "        sparse_prompt_embeddings=sparse_embeddings, # (B, 2, 256)\n",
    "        dense_prompt_embeddings=dense_embeddings, # (B, 256, 64, 64)\n",
    "        multimask_output=False,\n",
    "        )\n",
    "\n",
    "    low_res_pred = torch.sigmoid(low_res_logits)  # (1, 1, 256, 256)\n",
    "\n",
    "    low_res_pred = F.interpolate(\n",
    "        low_res_pred,\n",
    "        size=(H, W),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )  # (1, 1, gt.shape)\n",
    "    low_res_pred = low_res_pred.squeeze().cpu().numpy()  # (256, 256)\n",
    "    medsam_seg = (low_res_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "    return medsam_seg\n",
    "\n",
    "def pad_image_to_square(image_array):\n",
    "\n",
    "    original_shape = image_array.shape\n",
    "    \n",
    "    target_size = max(original_shape[:2])\n",
    "    \n",
    "    padding_needed = [(0, 0)] * len(original_shape)\n",
    "\n",
    "    for dim in range(2):\n",
    "        padding = (target_size - original_shape[dim]) // 2\n",
    "        extra_padding = (target_size - original_shape[dim]) % 2\n",
    "        padding_needed[dim] = (padding, padding + extra_padding)\n",
    "    \n",
    "    padded_img = np.pad(image_array, padding_needed, mode='constant', constant_values=0)\n",
    "\n",
    "    return padded_img\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "def resize_image(image_array, output_shape=(1024, 1024), interpolation='linear'):\n",
    "    if image_array.ndim == 2:\n",
    "        output_shape = output_shape[:2]\n",
    "    elif image_array.ndim == 3:\n",
    "        assert len(output_shape) == 3, \"Output shape must be 3-dimensional for 3-dimensional images.\"\n",
    "    \n",
    "    # 보간법 선택\n",
    "    anti_aliasing = interpolation == 'linear'\n",
    "    order = 0 if interpolation == 'nearest' else 1\n",
    "\n",
    "    resized_image = resize(image_array, output_shape, mode='reflect', anti_aliasing=anti_aliasing, order=order)\n",
    "\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f81eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load model and image\n",
    "MedSAM_CKPT_PATH = \"medsam_vit_b.pth\"\n",
    "device = \"cuda:0\"\n",
    "medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
    "medsam_model = medsam_model.to(device)\n",
    "medsam_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/workspace/data/VinDr-Mammo'\n",
    "img_root = os.path.join(root, 'nifti')\n",
    "bbox_root = os.path.join(root, 'bbox_nifti')\n",
    "pats = os.listdir(bbox_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3095cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_bbox = []\n",
    "error_crop = []\n",
    "\n",
    "for pat in tqdm(pats):\n",
    "    imgs = os.listdir(os.path.join(bbox_root, pat))\n",
    "    for img in imgs:\n",
    "        if \"Mass\" not in img:\n",
    "            continue\n",
    "        img_filename = \"_\".join(img.split(\"_\")[:2]) + \".nii.gz\"\n",
    "        img_path = os.path.join(img_root, pat, img_filename)\n",
    "        bbox_path = os.path.join(bbox_root, pat, img)\n",
    "        img_arr, spacing = Read_nifti(img_path)\n",
    "        bbox_arr, _ = Read_nifti(bbox_path)\n",
    "\n",
    "        if bbox_arr.sum() == 0:\n",
    "            print(pat, img, \",,,ERROR,,,empty bbox\")\n",
    "            empty_bbox.append(pat+\"_\"+img)\n",
    "            continue\n",
    "\n",
    "        mammogram, breast_mask, mass_bbox = crop(img_arr, bbox_arr)\n",
    "        minmax_normalized = minmax_normalization(mammogram)\n",
    "        trunc_normalized = truncation_normalization(mammogram, breast_mask)\n",
    "        cl2 = clahe(trunc_normalized, 0.01)\n",
    "\n",
    "        mammogram = np.stack([minmax_normalized, trunc_normalized, cl2], axis=2)\n",
    "\n",
    "        padded_mammogram = pad_image_to_square(mammogram)\n",
    "        padded_mass_bbox = pad_image_to_square(mass_bbox)\n",
    "        padded_breast_mask = pad_image_to_square(breast_mask)\n",
    "\n",
    "        if padded_mass_bbox.sum() == 0:\n",
    "            print(pat, img, \",,,ERROR,,,in cropping\")\n",
    "            error_crop.append(pat+\"_\"+img)\n",
    "            continue\n",
    "\n",
    "        mammogram_1024 = resize_image(padded_mammogram, output_shape=(1024, 1024,3), interpolation='linear')\n",
    "        mammogram_1024 = torch.tensor(mammogram_1024).float().permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "        \n",
    "        xmin = np.where(padded_mass_bbox==1)[0].min()\n",
    "        xmax = np.where(padded_mass_bbox==1)[0].max()\n",
    "        ymin = np.where(padded_mass_bbox==1)[1].min()\n",
    "        ymax = np.where(padded_mass_bbox==1)[1].max()\n",
    "        \n",
    "        box_np = np.array([[ymin, xmin, ymax, xmax]])\n",
    "        H, W = padded_mass_bbox.shape\n",
    "        box_1024 = box_np / np.array([W, H, W, H]) * 1024\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_embedding = medsam_model.image_encoder(mammogram_1024)\n",
    "        medsam_seg = medsam_inference(medsam_model, image_embedding, box_1024, H, W)\n",
    "        \n",
    "        xmin = np.where(padded_breast_mask==1)[0].min()\n",
    "        xmax = np.where(padded_breast_mask==1)[0].max()+1\n",
    "        ymin = np.where(padded_breast_mask==1)[1].min()\n",
    "        ymax = np.where(padded_breast_mask==1)[1].max()+1\n",
    "        \n",
    "        mammogram_arr = padded_mammogram[xmin:xmax,ymin:ymax, 0]\n",
    "        mass_bbox_arr = padded_mass_bbox[xmin:xmax,ymin:ymax]\n",
    "        breast_mask_arr = padded_breast_mask[xmin:xmax,ymin:ymax]\n",
    "        mass_mask_arr = medsam_seg[xmin:xmax,ymin:ymax]\n",
    "\n",
    "        pat_folder = os.path.join(root, 'cropped_nifti_mass', pat)\n",
    "        os.makedirs(pat_folder, exist_ok=True)\n",
    "        bbox_folder = os.path.join(root, 'cropped_bbox')\n",
    "        os.makedirs(bbox_folder, exist_ok=True)\n",
    "        mask_folder = os.path.join(root, 'cropped_mass')\n",
    "        os.makedirs(mask_folder, exist_ok=True)\n",
    "\n",
    "        mammogram_path = os.path.join(pat_folder, img_filename)\n",
    "        breast_mask_path = os.path.join(pat_folder, img_filename.split(\".\")[0]+\"-breask_mask.nii.gz\")\n",
    "        bbox_path = os.path.join(bbox_folder, pat+\"_\"+img)\n",
    "        mask_path = os.path.join(mask_folder, pat+\"_\"+img)\n",
    "\n",
    "        Save_nifti(mammogram_arr, mammogram_path, spacing=spacing)\n",
    "        Save_nifti(breast_mask_arr, breast_mask_path, spacing=spacing)\n",
    "        Save_nifti(mass_bbox_arr, bbox_path, spacing=spacing)\n",
    "        Save_nifti(mass_mask_arr, mask_path, spacing=spacing)\n",
    "\n",
    "        plot_path = os.path.join(root, 'cropped_check_mass', pat+\"_\"+img.split(\".\")[0]+\".png\")\n",
    "        os.makedirs(os.path.join(root, 'cropped_check_mass'), exist_ok=True)\n",
    "        save_comparison_images(img_arr, mammogram_arr, breast_mask_arr, plot_path, mass_mask_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fcd566",
   "metadata": {},
   "source": [
    "## Step 4: Extract Radiomics Features\n",
    "To ensure the mass is included in the input for the `stable-diffusion-2-inpainting` model, which requires an input size of (512,512), the image is resampled with 3x spacing. Radiomics features are then extracted from the resampled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af270d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import radiomics\n",
    "from radiomics import featureextractor, firstorder, glcm, imageoperations, shape, glszm\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "logger = radiomics.logging.getLogger(\"radiomics\")\n",
    "logger.setLevel(radiomics.logging.ERROR)\n",
    "\n",
    "def Shape_Feature_Extract(ID, image, ROI):\n",
    "    ShapeFeatureExtractor = radiomics.shape2D.RadiomicsShape2D(image, ROI, force2D=True)\n",
    "    ShapeFeatureExtractor.enableAllFeatures()\n",
    "    ShapeFeatureExtractor.execute()\n",
    "    \n",
    "    result = pd.DataFrame([ShapeFeatureExtractor.featureValues])\n",
    "    result.insert(loc=0, column='ID', value=ID)\n",
    "    result.columns = ['ID']+['Shape_'+x for x in list(result.columns[1:])]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def Hist_Feature_Extract(ID, image, ROI):\n",
    "    settings = {'binCount': 128, 'interpolator' : None, 'verbose' : True}\n",
    "    \n",
    "    HistFeatureExtractor = radiomics.firstorder.RadiomicsFirstOrder(image, ROI, **settings)\n",
    "    HistFeatureExtractor.enableAllFeatures()\n",
    "    HistFeatureExtractor.execute()\n",
    "    \n",
    "    result = pd.DataFrame([HistFeatureExtractor.featureValues])\n",
    "    result.insert(loc=0, column='ID', value=ID)\n",
    "    result.columns = ['ID']+['Hist_'+x for x in list(result.columns[1:])]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def GLCM_Feature_Extract(ID, image, ROI):\n",
    "    settings = {'binCount': 128, 'interpolator' : None, 'verbose' : True}\n",
    "    \n",
    "    GLCMFeatureExtractor = radiomics.glcm.RadiomicsGLCM(image, ROI, **settings)\n",
    "    GLCMFeatureExtractor.enableAllFeatures()\n",
    "    GLCMFeatureExtractor.execute()\n",
    "    \n",
    "    result = pd.DataFrame([GLCMFeatureExtractor.featureValues])\n",
    "    result.insert(loc=0, column='ID', value=ID)\n",
    "    result.columns = ['ID']+['GLCM_'+x for x in list(result.columns[1:])]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def GLSZM_Feature_Extract(ID, image, ROI):\n",
    "    settings = {'binCount': 128, 'interpolator' : None, 'verbose' : True}\n",
    "    \n",
    "    GLSZMFeatureExtractor = radiomics.glszm.RadiomicsGLSZM(image, ROI, **settings)\n",
    "    GLSZMFeatureExtractor.enableAllFeatures()\n",
    "    GLSZMFeatureExtractor.execute()\n",
    "    \n",
    "    result = pd.DataFrame([GLSZMFeatureExtractor.featureValues])\n",
    "    result.insert(loc=0, column='ID', value=ID)\n",
    "    result.columns = ['ID']+['GLSZM_'+x for x in list(result.columns[1:])]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def resize_image_and_roi(img_path, seg_path, breast_mask_path, resize_factor=3, crop_size=512):\n",
    "    img_sitk = sitk.ReadImage(img_path)\n",
    "    seg_sitk = sitk.ReadImage(seg_path)\n",
    "    breast_mask_sitk = sitk.ReadImage(breast_mask_path)\n",
    "    \n",
    "    original_size = img_sitk.GetSize()\n",
    "    original_spacing = img_sitk.GetSpacing()\n",
    "\n",
    "    new_size = [int(original_size[0] / resize_factor), int(original_size[1] / resize_factor)]\n",
    "    new_spacing = [original_spacing[0] * resize_factor, original_spacing[1] * resize_factor]\n",
    "\n",
    "    resample_img = sitk.Resample(img_sitk, new_size, sitk.Transform(), \n",
    "                                 sitk.sitkLinear, img_sitk.GetOrigin(),\n",
    "                                 new_spacing, img_sitk.GetDirection(), 0,\n",
    "                                 img_sitk.GetPixelID())\n",
    "\n",
    "    resample_seg = sitk.Resample(seg_sitk, new_size, sitk.Transform(), \n",
    "                                 sitk.sitkNearestNeighbor, seg_sitk.GetOrigin(),\n",
    "                                 new_spacing, seg_sitk.GetDirection(), 0,\n",
    "                                 seg_sitk.GetPixelID())\n",
    "\n",
    "    resample_breast_mask = sitk.Resample(breast_mask_sitk, new_size, sitk.Transform(), \n",
    "                                         sitk.sitkNearestNeighbor, breast_mask_sitk.GetOrigin(),\n",
    "                                         new_spacing, breast_mask_sitk.GetDirection(), 0,\n",
    "                                         breast_mask_sitk.GetPixelID())\n",
    "\n",
    "    return resample_img, resample_seg, resample_breast_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7e86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/workspace/data/VinDr-Mammo'\n",
    "img_root = os.path.join(root, 'cropped_nifti_mass')\n",
    "roi_root = os.path.join(root, \"cropped_mass\")\n",
    "save_root = os.path.join(root, \"Mass\")\n",
    "imgs = os.listdir(roi_root)\n",
    "\n",
    "os.makedirs(save_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4381f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_storage = dict()\n",
    "hist_storage = dict()\n",
    "glcm_storage = dict()\n",
    "glszm_storage = dict()\n",
    "\n",
    "Except_pat = dict()\n",
    "\n",
    "for i, img in enumerate(tqdm(imgs)):\n",
    "    try:\n",
    "        pat_id = img.split(\"_\")[0]\n",
    "        img_name = \"_\".join(img.split(\"_\")[1:3])\n",
    "        img_path = os.path.join(img_root, pat_id, img_name+\".nii.gz\")\n",
    "        breast_mask_path = os.path.join(img_root, pat_id, img_name+\"-breask_mask.nii.gz\")\n",
    "        seg_path = os.path.join(roi_root, img)\n",
    "        \n",
    "        img_sitk, seg_sitk, breast_mask_sitk = resize_image_and_roi(img_path, seg_path, breast_mask_path, resize_factor=3)\n",
    "        \n",
    "        shape = Shape_Feature_Extract(img, img_sitk, seg_sitk)\n",
    "        hist = Hist_Feature_Extract(img, img_sitk, seg_sitk)\n",
    "        glcm = GLCM_Feature_Extract(img, img_sitk, seg_sitk)\n",
    "        glszm = GLSZM_Feature_Extract(img, img_sitk, seg_sitk)\n",
    "\n",
    "    except:\n",
    "        print(\"### Fatal ERROR! ###\", img)\n",
    "        Except_pat[img] = \"ERROR\"\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "\n",
    "        isnan = False\n",
    "\n",
    "        shape = dict(shape.iloc[0,1:])\n",
    "        for f in shape:\n",
    "            shape[f] = float(shape[f])\n",
    "            if np.isnan(shape[f]):\n",
    "                isnan = True\n",
    "        hist = dict(hist.iloc[0,1:])\n",
    "        for f in hist:\n",
    "            hist[f] = float(hist[f])  \n",
    "            if np.isnan(hist[f]):\n",
    "                isnan = True\n",
    "        glcm = dict(glcm.iloc[0,1:])\n",
    "        for f in glcm:\n",
    "            glcm[f] = float(glcm[f])\n",
    "            if np.isnan(glcm[f]):\n",
    "                isnan = True\n",
    "        glszm = dict(glszm.iloc[0,1:])\n",
    "        for f in glszm:\n",
    "            glszm[f] = float(glszm[f])\n",
    "            if np.isnan(glszm[f]):\n",
    "                isnan = True\n",
    "\n",
    "        if isnan:\n",
    "            print(\"## ERROR in Nan! ###\", img)\n",
    "            Except_pat[img] = \"Nan\"\n",
    "            continue\n",
    "\n",
    "        shape_storage[img] = shape\n",
    "        hist_storage[img] = hist\n",
    "        glcm_storage[img] = glcm\n",
    "        glszm_storage[img] = glszm\n",
    "\n",
    "        os.makedirs(os.path.join(save_root, \"image\"), exist_ok=True)\n",
    "        sitk.WriteImage(img_sitk, os.path.join(save_root, \"image\", img))\n",
    "\n",
    "        os.makedirs(os.path.join(save_root, \"mask\"), exist_ok=True)\n",
    "        sitk.WriteImage(seg_sitk, os.path.join(save_root, \"mask\", img))\n",
    "\n",
    "        os.makedirs(os.path.join(save_root, \"breast_mask\"), exist_ok=True)\n",
    "        sitk.WriteImage(breast_mask_sitk, os.path.join(save_root, \"breast_mask\", img))\n",
    "\n",
    "        img_arr = sitk.GetArrayFromImage(img_sitk)\n",
    "        seg_arr = sitk.GetArrayFromImage(seg_sitk)\n",
    "        breast_mask_arr = sitk.GetArrayFromImage(breast_mask_sitk)\n",
    "\n",
    "        stacked_arr = np.stack([img_arr, breast_mask_arr, seg_arr], axis=0)\n",
    "        # stacked_arr = np.transpose(stacked_arr, (0,1,2))\n",
    "        stacked_sitk = sitk.GetImageFromArray(stacked_arr)\n",
    "        stacked_sitk.SetSpacing([seg_sitk.GetSpacing()[0], seg_sitk.GetSpacing()[1], 1])\n",
    "\n",
    "        os.makedirs(os.path.join(save_root, \"image_withMask\"), exist_ok=True)\n",
    "        sitk.WriteImage(stacked_sitk, os.path.join(save_root, \"image_withMask\", img))\n",
    "        \n",
    "        fileName = \"VinDr-Mammo_ExceptList_Extract2DpatchRadiomicsFeatures.json\"\n",
    "        file_path = os.path.join(save_root, fileName)\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(Except_pat, file, indent=4)\n",
    "\n",
    "print(Except_pat)\n",
    "fileName = \"VinDr-Mammo_ExceptList_Extract2DpatchRadiomicsFeatures.json\"\n",
    "file_path = os.path.join(save_root, fileName)\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(Except_pat, file, indent=4)\n",
    "\n",
    "df_shape = pd.DataFrame(shape_storage).T\n",
    "df_hist = pd.DataFrame(hist_storage).T\n",
    "df_glcm = pd.DataFrame(glcm_storage).T\n",
    "df_glszm = pd.DataFrame(glszm_storage).T\n",
    "\n",
    "df_shape.to_csv(os.path.join(save_root, \"shape.csv\"))\n",
    "df_hist.to_csv(os.path.join(save_root, \"hist.csv\"))\n",
    "df_glcm.to_csv(os.path.join(save_root, \"glcm.csv\"))\n",
    "df_glszm.to_csv(os.path.join(save_root, \"glszm.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42fcc7",
   "metadata": {},
   "source": [
    "### Split training/validation/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c66412",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/workspace/data/VinDr-Mammo'\n",
    "mass_root = os.path.join(root, \"Mass\")\n",
    "\n",
    "findings = pd.read_csv(os.path.join(root, 'finding_annotations+finding_num.csv'))\n",
    "\n",
    "density_mapping = {'DENSITY A': 1, 'DENSITY B': 2, 'DENSITY C':3, 'DENSITY D':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.path.join(mass_root, 'Mass_dataset_split.json')\n",
    "with open(json_path, 'r') as json_file:\n",
    "    Mass_dataset = json.load(json_file)\n",
    "\n",
    "print(len(Mass_dataset['trainset']), len(Mass_dataset['valset']), len(Mass_dataset['testset']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7158db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = pd.read_csv(os.path.join(mass_root, 'shape.csv'))\n",
    "hist = pd.read_csv(os.path.join(mass_root, 'hist.csv'))\n",
    "glcm = pd.read_csv(os.path.join(mass_root, 'glcm.csv'))\n",
    "glszm = pd.read_csv(os.path.join(mass_root, 'glszm.csv'))\n",
    "\n",
    "radiomics_features = pd.concat([shape, hist.iloc[:, 1:], glcm.iloc[:, 1:], glszm.iloc[:, 1:]], axis=1)\n",
    "radiomics_features.rename(columns = {'Unnamed: 0': 'ID'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe65f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = []\n",
    "assessments = []\n",
    "splits = []\n",
    "for index, row in radiomics_features.iterrows():\n",
    "    row_splits = row['ID'].split(\"_\")\n",
    "    pat_id = row_splits[0]\n",
    "    side = row_splits[1]\n",
    "    view = row_splits[2]\n",
    "#     print(pat_id, side, view)\n",
    "    density = density_mapping[findings[(findings['study_id']==pat_id) & (findings['laterality']==side) & (findings['view_position']==view)]['breast_density'].values[0]]\n",
    "    assessment = row_splits[4].split(\"-\")[-1]\n",
    "    split = findings[(findings['study_id']==pat_id) & (findings['laterality']==side) & (findings['view_position']==view)]['split'].values[0]\n",
    "    densities.append(density)\n",
    "    assessments.append(int(assessment))\n",
    "    # splits.append(split)\n",
    "    if pat_id in Mass_dataset['trainset']:\n",
    "        splits.append('training')\n",
    "    elif pat_id in Mass_dataset['valset']:\n",
    "        splits.append('validation')\n",
    "    elif pat_id in Mass_dataset['testset']:\n",
    "        splits.append('test')\n",
    "    \n",
    "radiomics_features[\"density\"] = densities\n",
    "radiomics_features[\"assessment\"] = assessments\n",
    "radiomics_features[\"split\"] = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "radiomics_features.loc[radiomics_features[\"density\"]<3, \"density\"] = 0 # low density\n",
    "radiomics_features.loc[radiomics_features[\"density\"]!=0, \"density\"] = 1 # high density\n",
    "\n",
    "radiomics_features.loc[radiomics_features[\"assessment\"]==3, \"assessment\"] = 1 # benign\n",
    "radiomics_features.loc[radiomics_features[\"assessment\"]!=1, \"assessment\"] = 2 # malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099934cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = radiomics_features[radiomics_features['split']=='training'].iloc[:, :-1]\n",
    "valset = radiomics_features[radiomics_features['split']=='validation'].iloc[:, :-1]\n",
    "testset = radiomics_features[radiomics_features['split']=='test'].iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf05f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.shape, valset.shape, testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.to_csv(os.path.join(mass_root, 'trainset.csv'), index=False)\n",
    "valset.to_csv(os.path.join(mass_root, 'valset.csv'), index=False)\n",
    "testset.to_csv(os.path.join(mass_root, 'testset.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdbe955",
   "metadata": {},
   "source": [
    "### Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39491a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/workspace/data/VinDr-Mammo'\n",
    "mass_root = os.path.join(root, \"Mass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c658035",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(os.path.join(mass_root, \"trainset.csv\"))\n",
    "valset = pd.read_csv(os.path.join(mass_root, \"valset.csv\"))\n",
    "testset = pd.read_csv(os.path.join(mass_root,\"testset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "columns_to_scale = trainset.columns[1:-2]\n",
    "print(len(columns_to_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4338fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[columns_to_scale] = scaler.fit_transform(trainset[columns_to_scale])\n",
    "valset[columns_to_scale] = scaler.transform(valset[columns_to_scale])\n",
    "testset[columns_to_scale] = scaler.transform(testset[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset['assessment'] = trainset['assessment'].astype(float)\n",
    "valset['assessment'] = valset['assessment'].astype(float)\n",
    "testset['assessment'] = testset['assessment'].astype(float)\n",
    "\n",
    "trainset.loc[trainset['assessment']==1, 'assessment'] = 0.5\n",
    "trainset.loc[trainset['assessment']==2, 'assessment'] = 1\n",
    "\n",
    "valset.loc[valset['assessment']==1, 'assessment'] = 0.5\n",
    "valset.loc[valset['assessment']==2, 'assessment'] = 1\n",
    "\n",
    "testset.loc[testset['assessment']==1, 'assessment'] = 0.5\n",
    "testset.loc[testset['assessment']==2, 'assessment'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f892af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.to_csv(os.path.join(mass_root, 'trainset_normalized.csv'), index=False)\n",
    "\n",
    "valset.to_csv(os.path.join(mass_root,'valset_normalized.csv'), index=False)\n",
    "\n",
    "testset.to_csv(os.path.join(mass_root,'testset_normalized.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bdd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_dict = dict()\n",
    "\n",
    "for i, col in enumerate(columns_to_scale):\n",
    "    min_max_dict[col] = [scaler.data_min_[i], scaler.data_max_[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_dict_path = os.path.join(mass_root, \"min_max_dict.json\")\n",
    "with open(min_max_dict_path, 'w') as file:\n",
    "    json.dump(min_max_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f082b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_data_list = [\n",
    "    [\"Low_Density\"]+[0]*67+[1]+[0],\n",
    "    [\"High_Density\"]+[0]*67+[0]+[0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f794c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_rows = pd.DataFrame(Normal_data_list, columns=trainset.columns)\n",
    "\n",
    "new_trainset = pd.concat([trainset, normal_rows], ignore_index=True)\n",
    "new_valset = pd.concat([valset, normal_rows], ignore_index=True)\n",
    "new_testset = pd.concat([testset, normal_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009906c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trainset.to_csv(os.path.join(root, \"trainset_normalized_6cls.csv\"), index=False)\n",
    "new_valset.to_csv(os.path.join(root, \"valset_normalized_6cls.csv\"), index=False)\n",
    "new_testset.to_csv(os.path.join(root, \"testset_normalized_6cls.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a9399",
   "metadata": {},
   "source": [
    "## Step 5: Preprocessing for Normal cases\n",
    "\n",
    "Only \"No Finding\" cases are used as Normal cases, excluding not only mass findings but also Suspicious Calcification findings, which are not covered in this paper. As with mass cases, images are resampled with 3x spacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292dabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_and_roi(img_path, breast_mask_path, resize_factor=3, crop_size=512):\n",
    "    img_sitk = sitk.ReadImage(img_path)\n",
    "    breast_mask_sitk = sitk.ReadImage(breast_mask_path)\n",
    "    \n",
    "    original_size = img_sitk.GetSize()\n",
    "    original_spacing = img_sitk.GetSpacing()\n",
    "\n",
    "    new_size = [int(original_size[0] / resize_factor), int(original_size[1] / resize_factor)]\n",
    "    new_spacing = [original_spacing[0] * resize_factor, original_spacing[1] * resize_factor]\n",
    "\n",
    "    resample_img = sitk.Resample(img_sitk, new_size, sitk.Transform(), \n",
    "                                 sitk.sitkLinear, img_sitk.GetOrigin(),\n",
    "                                 new_spacing, img_sitk.GetDirection(), 0,\n",
    "                                 img_sitk.GetPixelID())\n",
    "\n",
    "    resample_breast_mask = sitk.Resample(breast_mask_sitk, new_size, sitk.Transform(), \n",
    "                                         sitk.sitkNearestNeighbor, breast_mask_sitk.GetOrigin(),\n",
    "                                         new_spacing, breast_mask_sitk.GetDirection(), 0,\n",
    "                                         breast_mask_sitk.GetPixelID())\n",
    "\n",
    "    return resample_img, resample_breast_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/workspace/data/VinDr-Mammo'\n",
    "normal_root = os.path.join(root, \"Normal\")\n",
    "os.makedirs(normal_root, exist_ok=True)\n",
    "\n",
    "findings = pd.read_csv(os.path.join(root, 'finding_annotations.csv'))\n",
    "normal = findings[findings['finding_categories']==\"['No Finding']\"]\n",
    "\n",
    "json_path = os.path.join(root, 'Mass', 'Mass_dataset_split.json')\n",
    "with open(json_path, 'r') as json_file:\n",
    "    Mass_dataset = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = []\n",
    "test_list = []\n",
    "\n",
    "for index, row in tqdm(normal.iterrows()):\n",
    "    if row['study_id'] in Mass_dataset['trainset']:\n",
    "        continue\n",
    "    elif row['study_id'] in Mass_dataset['valset']:\n",
    "        continue\n",
    "    elif row['study_id'] in Mass_dataset['testset']:\n",
    "        continue\n",
    "    pat_id = row['study_id']\n",
    "    if row['split'] == 'training':\n",
    "        training_list.append(pat_id)\n",
    "    elif row['split'] == 'test':\n",
    "        test_list.append(pat_id)\n",
    "\n",
    "training_list = list(set(training_list))\n",
    "test_list = list(set(test_list))\n",
    "len(training_list), len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32855ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num = int(len(training_list) * 0.1)\n",
    "val_list = random.sample(training_list, val_num)\n",
    "training_list = list(set(training_list) - set(val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa72ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_list), len(test_list), len(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bdc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_dataset = dict()\n",
    "Normal_dataset['trainset'] = training_list\n",
    "Normal_dataset['valset'] = val_list\n",
    "Normal_dataset['testset'] = test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bdfb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_path = os.path.join(root, 'Normal', 'Normal_dataset_split.json')\n",
    "# with open(json_path, 'w') as json_file:\n",
    "#     json.dump(Normal_dataset, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b19d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_root = os.path.join(root, 'cropped_nifti')\n",
    "\n",
    "pats = os.listdir(img_root)\n",
    "\n",
    "for pat in tqdm(pats):\n",
    "    if pat in Normal_dataset['trainset'] or pat in Normal_dataset['valset'] or pat in Normal_dataset['testset']:\n",
    "        imgs = os.listdir(os.path.join(img_root, pat))\n",
    "        for img in imgs:\n",
    "            if (\"-breask_mask.nii.gz\" in img) or (\".nii.gz\" not in img):\n",
    "                continue\n",
    "            img_path = os.path.join(img_root, pat, img)\n",
    "            breast_mask_path = os.path.join(img_root, pat, img.split(\".\")[0]+\"-breask_mask.nii.gz\")\n",
    "            img_sitk, breast_mask_sitk = resize_image_and_roi(img_path, breast_mask_path)\n",
    "            \n",
    "            os.makedirs(os.path.join(normal_root, \"image\"), exist_ok=True)\n",
    "            sitk.WriteImage(img_sitk, os.path.join(normal_root, \"image\", pat+\"_\"+img))\n",
    "\n",
    "            os.makedirs(os.path.join(normal_root, \"breast_mask\"), exist_ok=True)\n",
    "            sitk.WriteImage(breast_mask_sitk, os.path.join(normal_root, \"breast_mask\", pat+\"_\"+img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5107c4",
   "metadata": {},
   "source": [
    "# Step 6: Register Opposite-Side Image\n",
    "\n",
    "To provide additional normal tissue information during inpainting, we use the opposite-side image due to the symmetrical nature of normal tissue in mammograms. The opposite-side image is rigidly registered using ANTs (refer to separate code)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
